{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/tfp8h_wd35n8t6c1bystkdph0000gn/T/ipykernel_90937/2917849246.py:10: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_2018 = pd.read_csv(file_2018)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 2018 dataset:\n",
      "['timestamp', 'Dst Port', 'protocol', 'Flow Duration', 'Flow Duration_rolling_mean', 'Flow Duration_rolling_std', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Max', 'Fwd IAT Min', 'SYN Flag Cnt', 'pkts_ratio', 'byte_per_duration', 'entropy_pkt_len', 'Subflow Fwd Byts', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'label']\n",
      "\n",
      "Columns in 2019 dataset:\n",
      "['timestamp', 'Dst Port', 'protocol', 'Flow Duration', 'Flow Duration_rolling_mean', 'Flow Duration_rolling_std', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Max', 'Fwd IAT Min', 'SYN Flag Cnt', 'pkts_ratio', 'byte_per_duration', 'entropy_pkt_len', 'Subflow Fwd Byts', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Max', 'Bwd IAT Min', 'Flow Bytes/s', 'Flow Packets/s', 'label']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "file_2018 = \"/Users/rooj/Documents/RP3-Main/RP3-Data/clean-datasets/2018.csv\"  # Update with your actual path\n",
    "file_2019 = \"/Users/rooj/Documents/RP3-Main/RP3-Data/clean-datasets/2019.csv\"  # Update with your actual path\n",
    "\n",
    "# Load the datasets\n",
    "df_2018 = pd.read_csv(file_2018)\n",
    "df_2019 = pd.read_csv(file_2019)\n",
    "\n",
    "# Standardize column names (strip extra whitespace)\n",
    "df_2018.columns = df_2018.columns.str.strip()\n",
    "df_2019.columns = df_2019.columns.str.strip()\n",
    "\n",
    "# Print column names to compare\n",
    "print(\"Columns in 2018 dataset:\")\n",
    "print(df_2018.columns.tolist())\n",
    "\n",
    "print(\"\\nColumns in 2019 dataset:\")\n",
    "print(df_2019.columns.tolist())\n",
    "\n",
    "# Define the desired column order based on the 2018 dataset\n",
    "desired_order = ['timestamp', 'Dst Port', 'protocol', 'Flow Duration', \n",
    "                 'Flow Duration_rolling_mean', 'Flow Duration_rolling_std', \n",
    "                 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', \n",
    "                 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', \n",
    "                 'Fwd Pkt Len Std', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Max', \n",
    "                 'Fwd IAT Min', 'SYN Flag Cnt', 'pkts_ratio', 'byte_per_duration', \n",
    "                 'entropy_pkt_len', 'Subflow Fwd Byts', 'Bwd Pkt Len Max', \n",
    "                 'Bwd Pkt Len Min', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following common columns:\n",
      "['timestamp', 'Dst Port', 'protocol', 'Flow Duration', 'Flow Duration_rolling_mean', 'Flow Duration_rolling_std', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Max', 'Fwd IAT Min', 'SYN Flag Cnt', 'pkts_ratio', 'byte_per_duration', 'entropy_pkt_len', 'Subflow Fwd Byts', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'label']\n",
      "\n",
      "Duplicates in 2018 common data: 39279\n",
      "Duplicates in 2019 common data: 1611\n"
     ]
    }
   ],
   "source": [
    "# Get the intersection of columns in both datasets and keep the desired order\n",
    "common_desired = [col for col in desired_order if col in df_2018.columns and col in df_2019.columns]\n",
    "print(\"Using the following common columns:\")\n",
    "print(common_desired)\n",
    "\n",
    "# Subset the DataFrames to only include the common desired columns\n",
    "df_2018_common = df_2018[common_desired]\n",
    "df_2019_common = df_2019[common_desired]\n",
    "\n",
    "# Check duplicates in each subset (optional)\n",
    "print(\"\\nDuplicates in 2018 common data:\", df_2018_common.duplicated().sum())\n",
    "print(\"Duplicates in 2019 common data:\", df_2019_common.duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/tfp8h_wd35n8t6c1bystkdph0000gn/T/ipykernel_90937/1247725278.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019_common['timestamp'] = pd.to_datetime(df_2019_common['timestamp'], errors='coerce')\n",
      "/var/folders/_f/tfp8h_wd35n8t6c1bystkdph0000gn/T/ipykernel_90937/1247725278.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019_common['date'] = df_2019_common['timestamp'].dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning, 2018 shape: (4339650, 27)\n",
      "Unique dates in 2018 after cleaning:\n",
      "[datetime.date(2018, 2, 16) datetime.date(2018, 2, 20)\n",
      " datetime.date(2018, 2, 21) datetime.date(2018, 2, 15)]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Timestamp conversion for 2018 and 2019\n",
    "# ---------------------------\n",
    "# For 2018, we expect numeric timestamps; for 2019, they may already be datetime.\n",
    "if pd.api.types.is_numeric_dtype(df_2018_common['timestamp']):\n",
    "    df_2018_common['timestamp'] = pd.to_datetime(df_2018_common['timestamp'], unit='s', errors='coerce')\n",
    "else:\n",
    "    df_2018_common['timestamp'] = pd.to_datetime(df_2018_common['timestamp'], errors='coerce')\n",
    "\n",
    "if pd.api.types.is_numeric_dtype(df_2019_common['timestamp']):\n",
    "    df_2019_common['timestamp'] = pd.to_datetime(df_2019_common['timestamp'], unit='s', errors='coerce')\n",
    "else:\n",
    "    df_2019_common['timestamp'] = pd.to_datetime(df_2019_common['timestamp'], errors='coerce')\n",
    "\n",
    "# Optionally, extract the date\n",
    "df_2018_common['date'] = df_2018_common['timestamp'].dt.date\n",
    "df_2019_common['date'] = df_2019_common['timestamp'].dt.date\n",
    "\n",
    "# For 2018, drop rows where timestamp conversion failed (NaT)\n",
    "df_2018_cleaned = df_2018_common.dropna(subset=['timestamp']).reset_index(drop=True)\n",
    "print(\"\\nAfter cleaning, 2018 shape:\", df_2018_cleaned.shape)\n",
    "print(\"Unique dates in 2018 after cleaning:\")\n",
    "print(df_2018_cleaned['timestamp'].dt.date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset shape (before reordering columns): (35485591, 27)\n",
      "Number of duplicate rows in combined dataset: 40890\n"
     ]
    }
   ],
   "source": [
    "# Merge the cleaned 2018 data with 2019 common data (without altering the original order)\n",
    "df_combined = pd.concat([df_2018_cleaned, df_2019_common], ignore_index=True)\n",
    "print(\"\\nCombined dataset shape (before reordering columns):\", df_combined.shape)\n",
    "print(\"Number of duplicate rows in combined dataset:\", df_combined.duplicated().sum())\n",
    "\n",
    "# Reorder the columns of the combined dataset to match desired_order\n",
    "# We keep only those columns from desired_order that are present in df_combined.\n",
    "final_columns = [col for col in desired_order if col in df_combined.columns]\n",
    "df_combined = df_combined[final_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final merged dataset (first 10 rows):\n",
      "            timestamp  Dst Port protocol  Flow Duration  \\\n",
      "0 2018-02-16 01:48:36   55250.0      6.0       958807.0   \n",
      "1 2018-02-20 04:10:48     443.0      6.0      6081730.0   \n",
      "2 2018-02-21 02:25:01   52453.0      6.0         1428.0   \n",
      "3 2018-02-15 01:55:28    3389.0      6.0      2169521.0   \n",
      "4 2018-02-20 08:47:36   49913.0      6.0           97.0   \n",
      "5 2018-02-20 08:50:54     443.0      6.0    116813592.0   \n",
      "6 2018-02-21 02:26:13   57795.0      6.0         1279.0   \n",
      "7 2018-02-20 02:50:02      53.0     17.0          755.0   \n",
      "8 2018-02-20 11:58:21      80.0      6.0          602.0   \n",
      "9 2018-02-15 11:49:02     443.0      6.0     62405442.0   \n",
      "\n",
      "   Flow Duration_rolling_mean  Flow Duration_rolling_std  Tot Fwd Pkts  \\\n",
      "0                   1815614.1               1.965582e+06           5.0   \n",
      "1                   2284039.7               2.888929e+06          10.0   \n",
      "2                      6703.5               8.135168e+03           5.0   \n",
      "3                   9191415.4               2.752269e+07           8.0   \n",
      "4                  24709922.5               4.818137e+07           3.0   \n",
      "5                  73916199.6               5.294507e+07          15.0   \n",
      "6                      6738.6               9.250607e+03           5.0   \n",
      "7                     24525.7               3.559704e+04           1.0   \n",
      "8                  23284918.0               3.834917e+07           3.0   \n",
      "9                  29679624.9               3.933580e+07          16.0   \n",
      "\n",
      "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  ...  Fwd IAT Max  \\\n",
      "0           3.0            935.0            350.0  ...     900031.0   \n",
      "1          12.0            646.0           3485.0  ...    6012556.0   \n",
      "2           2.0            935.0            287.0  ...       1087.0   \n",
      "3           7.0           1132.0           1581.0  ...    1204083.0   \n",
      "4           1.0             31.0              0.0  ...         73.0   \n",
      "5          19.0           1074.0           7266.0  ...   58302441.0   \n",
      "6           2.0            935.0            299.0  ...       1049.0   \n",
      "7           1.0             45.0             73.0  ...          0.0   \n",
      "8           4.0            161.0            488.0  ...        201.0   \n",
      "9          18.0           1155.0           7229.0  ...   58913962.0   \n",
      "\n",
      "   Fwd IAT Min  SYN Flag Cnt  pkts_ratio  byte_per_duration  entropy_pkt_len  \\\n",
      "0         25.0           0.0    1.666667       1.340207e+03         0.883617   \n",
      "1       1036.0           0.0    0.833333       6.792475e+02         0.530309   \n",
      "2          9.0           0.0    2.500000       8.557423e+05         1.112688   \n",
      "3         49.0           0.0    1.142857       1.250506e+03         0.001134   \n",
      "4         24.0           0.0    3.000000       3.195876e+05         0.529480   \n",
      "5         41.0           0.0    0.789474       7.139580e+01         0.530309   \n",
      "6          7.0           0.0    2.500000       9.648163e+05         1.112688   \n",
      "7          0.0           0.0    1.000000       1.562914e+05         0.530309   \n",
      "8        116.0           0.0    0.750000       1.078073e+06         0.553285   \n",
      "9         38.0           0.0    0.888889       1.343473e+02         0.001134   \n",
      "\n",
      "   Subflow Fwd Byts  Bwd Pkt Len Max  Bwd Pkt Len Min   label  \n",
      "0             935.0            350.0              0.0  Benign  \n",
      "1             646.0           1432.0              0.0  Benign  \n",
      "2             935.0            287.0              0.0  Benign  \n",
      "3            1132.0           1173.0              0.0  Benign  \n",
      "4              31.0              0.0              0.0  Benign  \n",
      "5            1074.0           1460.0              0.0  Benign  \n",
      "6             935.0            299.0              0.0  Benign  \n",
      "7              45.0             73.0             73.0  Benign  \n",
      "8             161.0            488.0              0.0  Benign  \n",
      "9            1155.0           1460.0              0.0  Benign  \n",
      "\n",
      "[10 rows x 26 columns]\n",
      "\n",
      "First 10 rows of the 2018_cleaned dataset:\n",
      "            timestamp  Dst Port protocol  Flow Duration  \\\n",
      "0 2018-02-16 01:48:36   55250.0      6.0       958807.0   \n",
      "1 2018-02-20 04:10:48     443.0      6.0      6081730.0   \n",
      "2 2018-02-21 02:25:01   52453.0      6.0         1428.0   \n",
      "3 2018-02-15 01:55:28    3389.0      6.0      2169521.0   \n",
      "4 2018-02-20 08:47:36   49913.0      6.0           97.0   \n",
      "5 2018-02-20 08:50:54     443.0      6.0    116813592.0   \n",
      "6 2018-02-21 02:26:13   57795.0      6.0         1279.0   \n",
      "7 2018-02-20 02:50:02      53.0     17.0          755.0   \n",
      "8 2018-02-20 11:58:21      80.0      6.0          602.0   \n",
      "9 2018-02-15 11:49:02     443.0      6.0     62405442.0   \n",
      "\n",
      "   Flow Duration_rolling_mean  Flow Duration_rolling_std  Tot Fwd Pkts  \\\n",
      "0                   1815614.1               1.965582e+06           5.0   \n",
      "1                   2284039.7               2.888929e+06          10.0   \n",
      "2                      6703.5               8.135168e+03           5.0   \n",
      "3                   9191415.4               2.752269e+07           8.0   \n",
      "4                  24709922.5               4.818137e+07           3.0   \n",
      "5                  73916199.6               5.294507e+07          15.0   \n",
      "6                      6738.6               9.250607e+03           5.0   \n",
      "7                     24525.7               3.559704e+04           1.0   \n",
      "8                  23284918.0               3.834917e+07           3.0   \n",
      "9                  29679624.9               3.933580e+07          16.0   \n",
      "\n",
      "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  ...  Fwd IAT Min  \\\n",
      "0           3.0            935.0            350.0  ...         25.0   \n",
      "1          12.0            646.0           3485.0  ...       1036.0   \n",
      "2           2.0            935.0            287.0  ...          9.0   \n",
      "3           7.0           1132.0           1581.0  ...         49.0   \n",
      "4           1.0             31.0              0.0  ...         24.0   \n",
      "5          19.0           1074.0           7266.0  ...         41.0   \n",
      "6           2.0            935.0            299.0  ...          7.0   \n",
      "7           1.0             45.0             73.0  ...          0.0   \n",
      "8           4.0            161.0            488.0  ...        116.0   \n",
      "9          18.0           1155.0           7229.0  ...         38.0   \n",
      "\n",
      "   SYN Flag Cnt  pkts_ratio  byte_per_duration  entropy_pkt_len  \\\n",
      "0           0.0    1.666667       1.340207e+03         0.883617   \n",
      "1           0.0    0.833333       6.792475e+02         0.530309   \n",
      "2           0.0    2.500000       8.557423e+05         1.112688   \n",
      "3           0.0    1.142857       1.250506e+03         0.001134   \n",
      "4           0.0    3.000000       3.195876e+05         0.529480   \n",
      "5           0.0    0.789474       7.139580e+01         0.530309   \n",
      "6           0.0    2.500000       9.648163e+05         1.112688   \n",
      "7           0.0    1.000000       1.562914e+05         0.530309   \n",
      "8           0.0    0.750000       1.078073e+06         0.553285   \n",
      "9           0.0    0.888889       1.343473e+02         0.001134   \n",
      "\n",
      "   Subflow Fwd Byts  Bwd Pkt Len Max  Bwd Pkt Len Min   label        date  \n",
      "0             935.0            350.0              0.0  Benign  2018-02-16  \n",
      "1             646.0           1432.0              0.0  Benign  2018-02-20  \n",
      "2             935.0            287.0              0.0  Benign  2018-02-21  \n",
      "3            1132.0           1173.0              0.0  Benign  2018-02-15  \n",
      "4              31.0              0.0              0.0  Benign  2018-02-20  \n",
      "5            1074.0           1460.0              0.0  Benign  2018-02-20  \n",
      "6             935.0            299.0              0.0  Benign  2018-02-21  \n",
      "7              45.0             73.0             73.0  Benign  2018-02-20  \n",
      "8             161.0            488.0              0.0  Benign  2018-02-20  \n",
      "9            1155.0           1460.0              0.0  Benign  2018-02-15  \n",
      "\n",
      "[10 rows x 27 columns]\n",
      "\n",
      "First 10 rows of the 2019_common dataset:\n",
      "                      timestamp  Dst Port  protocol  Flow Duration  \\\n",
      "0 2018-12-01 13:04:45.928673029      4463      17.0            1.0   \n",
      "1 2018-12-01 13:04:45.928913116      9914      17.0            1.0   \n",
      "2 2018-12-01 13:04:45.928915024     32361      17.0            2.0   \n",
      "3 2018-12-01 13:04:45.929023981      5691      17.0            2.0   \n",
      "4 2018-12-01 13:04:45.929095984     56335      17.0            1.0   \n",
      "5 2018-12-01 13:04:45.929169893     57615      17.0       106422.0   \n",
      "6 2018-12-01 13:04:45.929172039     34159      17.0            1.0   \n",
      "7 2018-12-01 13:04:45.929287910     12269      17.0            1.0   \n",
      "8 2018-12-01 13:04:45.929378986     36639      17.0            1.0   \n",
      "9 2018-12-01 13:04:45.929380894     36368      17.0       989278.0   \n",
      "\n",
      "   Flow Duration_rolling_mean  Flow Duration_rolling_std  Tot Fwd Pkts  \\\n",
      "0                    1.000000                   0.000000           2.0   \n",
      "1                    1.000000                   0.000000           2.0   \n",
      "2                    1.333333                   0.577350           2.0   \n",
      "3                    1.500000                   0.577350           2.0   \n",
      "4                    1.400000                   0.547723           2.0   \n",
      "5                17738.166667               43446.028023           4.0   \n",
      "6                15204.285714               40223.231197           2.0   \n",
      "7                13303.875000               37625.404368           2.0   \n",
      "8                11825.777778               35473.583336           2.0   \n",
      "9               109571.000000              310901.657008          20.0   \n",
      "\n",
      "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  ...  Fwd IAT Min  \\\n",
      "0           0.0            766.0              0.0  ...          1.0   \n",
      "1           0.0            778.0              0.0  ...          1.0   \n",
      "2           0.0            750.0              0.0  ...          2.0   \n",
      "3           0.0            738.0              0.0  ...          2.0   \n",
      "4           0.0            750.0              0.0  ...          1.0   \n",
      "5           0.0           1438.0              0.0  ...          1.0   \n",
      "6           0.0            778.0              0.0  ...          1.0   \n",
      "7           0.0            738.0              0.0  ...          1.0   \n",
      "8           0.0            750.0              0.0  ...          1.0   \n",
      "9           0.0           7242.0              0.0  ...          1.0   \n",
      "\n",
      "   SYN Flag Cnt  pkts_ratio  byte_per_duration  entropy_pkt_len  \\\n",
      "0           0.0         0.0       7.660000e+08         0.502868   \n",
      "1           0.0         0.0       7.780000e+08         0.502868   \n",
      "2           0.0         0.0       3.750000e+08         0.502868   \n",
      "3           0.0         0.0       3.690000e+08         0.502868   \n",
      "4           0.0         0.0       7.500000e+08         0.502868   \n",
      "5           0.0         0.0       1.351224e+04         0.502868   \n",
      "6           0.0         0.0       7.780000e+08         0.502868   \n",
      "7           0.0         0.0       7.380000e+08         0.502868   \n",
      "8           0.0         0.0       7.500000e+08         0.502868   \n",
      "9           0.0         0.0       7.320490e+03         0.502868   \n",
      "\n",
      "   Subflow Fwd Byts  Bwd Pkt Len Max  Bwd Pkt Len Min    label        date  \n",
      "0             766.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "1             778.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "2             750.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "3             738.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "4             750.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "5            1438.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "6             778.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "7             738.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "8             750.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "9            7242.0              0.0              0.0  UDP-lag  2018-12-01  \n",
      "\n",
      "[10 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal merged dataset (first 10 rows):\")\n",
    "print(df_combined.head(10))\n",
    "\n",
    "print(\"\\nFirst 10 rows of the 2018_cleaned dataset:\")\n",
    "print(df_2018_cleaned.head(10))\n",
    "\n",
    "print(\"\\nFirst 10 rows of the 2019_common dataset:\")\n",
    "print(df_2019_common.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset saved to: Combined_Datasets/combined_2018_2019.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the output folder and path\n",
    "output_folder = \"Combined_Datasets\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, \"combined_2018_2019.csv\")\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "print(\"\\nCombined dataset saved to:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
